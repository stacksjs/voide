<template>
  <div class="max-w-3xl mx-auto w-full">
    <!-- Thinking indicator - shown above input when processing -->
    <div id="thinkingIndicator" class="hidden mb-3 px-4">
      <div class="flex items-center gap-2 text-monokai-gray/70">
        <div class="flex gap-1">
          <span class="w-1.5 h-1.5 bg-monokai-purple rounded-full animate-bounce" style="animation-delay: 0ms"></span>
          <span class="w-1.5 h-1.5 bg-monokai-purple rounded-full animate-bounce" style="animation-delay: 150ms"></span>
          <span class="w-1.5 h-1.5 bg-monokai-purple rounded-full animate-bounce" style="animation-delay: 300ms"></span>
        </div>
        <span class="text-sm italic">thinking...</span>
        <span id="thinkingTimer" class="opacity-40 font-mono" style="font-size: 10px">0.0s</span>
      </div>
    </div>

    <div
      id="inputContainer"
      class="bg-monokai-bg-dark border border-monokai-border rounded-2xl px-4 py-3"
    >
      <!-- Input row -->
      <div class="flex items-end gap-3">
        <textarea
          id="textInput"
          class="flex-1 bg-transparent text-sm text-monokai-fg border-none outline-none resize-none min-h-[24px] max-h-[160px] leading-6 placeholder-monokai-gray"
          placeholder="Type / for commands"
          rows="1"
        ></textarea>
      </div>

      <!-- Bottom bar -->
      <div class="flex items-center justify-between mt-3 pt-3 border-t border-monokai-border/50">
        <div class="flex items-center gap-2">
          <!-- Attachment button (placeholder) -->
          <button
            class="w-8 h-8 rounded-lg flex items-center justify-center text-monokai-gray hover:text-monokai-fg hover:bg-monokai-bg transition-colors"
            title="Attach file"
          >
            <svg class="w-4 h-4" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M12 4.5v15m7.5-7.5h-15"></path></svg>
          </button>

          <!-- Voice button -->
          <button
            id="micButton"
            class="w-8 h-8 rounded-lg flex items-center justify-center text-monokai-gray hover:text-monokai-fg hover:bg-monokai-bg transition-colors"
            title="Voice input (Space)"
          >
            <svg id="micIcon" class="w-4 h-4" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M12 18.75a6 6 0 006-6v-1.5m-6 7.5a6 6 0 01-6-6v-1.5m6 7.5v3.75m-3.75 0h7.5M12 15.75a3 3 0 01-3-3V4.5a3 3 0 116 0v8.25a3 3 0 01-3 3z"></path></svg>
          </button>

          <!-- Driving Mode toggle -->
          <button
            id="drivingModeBtn"
            class="w-8 h-8 rounded-lg flex items-center justify-center text-monokai-gray hover:text-monokai-fg hover:bg-monokai-bg transition-colors"
            title="Driving Mode (hands-free)"
          >
            <svg id="drivingIcon" class="w-4 h-4" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M8.25 18.75a1.5 1.5 0 01-3 0m3 0a1.5 1.5 0 00-3 0m3 0h6m-9 0H3.375a1.125 1.125 0 01-1.125-1.125V14.25m17.25 4.5a1.5 1.5 0 01-3 0m3 0a1.5 1.5 0 00-3 0m3 0h1.125c.621 0 1.129-.504 1.09-1.124a17.902 17.902 0 00-3.213-9.193 2.056 2.056 0 00-1.58-.86H14.25M16.5 18.75h-2.25m0-11.177v-.958c0-.568-.422-1.048-.987-1.106a48.554 48.554 0 00-10.026 0 1.106 1.106 0 00-.987 1.106v7.635m12-6.677v6.677m0 4.5v-4.5m0 0h-12"></path></svg>
          </button>

          <!-- Stop button (shown when processing) -->
          <button
            id="stopBtn"
            class="hidden w-8 h-8 rounded-lg flex items-center justify-center bg-monokai-pink/20 text-monokai-pink hover:bg-monokai-pink/30 transition-colors"
            title="Stop"
          >
            <svg class="w-4 h-4" fill="currentColor" viewBox="0 0 24 24"><rect x="6" y="6" width="12" height="12" rx="2"></rect></svg>
          </button>
        </div>

        <div class="flex items-center gap-3">
          <!-- Driver selector -->
          <select
            id="driverSelect"
            class="bg-transparent text-sm text-monokai-fg/70 border-none outline-none cursor-pointer"
          >
            <option value="claude-sdk">Claude</option>
            <option value="openai">OpenAI</option>
            <option value="ollama">Ollama</option>
          </select>

          <!-- Send button -->
          <button
            id="sendBtn"
            class="w-8 h-8 rounded-lg bg-monokai-yellow flex items-center justify-center cursor-pointer hover:bg-monokai-yellow/90 transition-colors"
            title="Send (Enter)"
          >
            <svg class="w-4 h-4" fill="none" stroke="#1e1e1e" stroke-width="2.5" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M4.5 10.5L12 3m0 0l7.5 7.5M12 3v18"></path></svg>
          </button>
        </div>
      </div>
    </div>

    <!-- Recording indicator -->
    <div id="recordingIndicator" class="hidden mt-2 text-center">
      <span class="text-xs text-monokai-pink animate-pulse">Listening...</span>
    </div>
  </div>
</template>

<script client>
(() => {
  const API_BASE_URL = 'http://localhost:3008/voide';

  function init() {
    const stores = window.VoideStores;
    if (!stores) {
      setTimeout(init, 10);
      return;
    }

    const { appStore, appActions, chatStore, chatActions, settingsStore, settingsActions } = stores;

    // Speech recognition setup - continuous: true keeps mic on until user stops it
    const speechRecognition = stores.useSpeechRecognition({
      continuous: true,
      interimResults: true,
      lang: 'en-US'
    });

    let accumulatedTranscript = '';
    let lastProcessedTranscript = ''; // Track last processed to prevent exact duplicates
    let isRestarting = false; // Flag to prevent race conditions during restart
    let isSending = false; // Flag to prevent duplicate sends
    let lastSendTime = 0; // Timestamp to debounce sends

    // Driving mode state
    let isDrivingMode = false;
    let isAwake = false; // Wake word state for driving mode
    let audioContext = null;

    // =========================================================================
    // Audio Cues (Web Audio API)
    // =========================================================================

    function getAudioContext() {
      if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
      }
      return audioContext;
    }

    function playTone(frequency, duration, type = 'sine', volume = 0.3) {
      try {
        const ctx = getAudioContext();
        const oscillator = ctx.createOscillator();
        const gain = ctx.createGain();

        oscillator.type = type;
        oscillator.frequency.value = frequency;
        oscillator.connect(gain);
        gain.connect(ctx.destination);

        gain.gain.setValueAtTime(volume, ctx.currentTime);
        gain.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + duration);

        oscillator.start();
        oscillator.stop(ctx.currentTime + duration);
      } catch (e) {
        console.log('[Audio] Could not play tone:', e);
      }
    }

    // Sound effects for driving mode
    const sounds = {
      // Quick high ping - listening activated
      listening: () => playTone(880, 0.12, 'sine', 0.25),

      // Soft processing indicator
      processing: () => playTone(440, 0.2, 'sine', 0.15),

      // Pleasant two-note chime - done
      done: () => {
        playTone(660, 0.15, 'sine', 0.2);
        setTimeout(() => playTone(880, 0.25, 'sine', 0.25), 150);
      },

      // Descending tone - error
      error: () => {
        playTone(440, 0.15, 'sine', 0.2);
        setTimeout(() => playTone(280, 0.25, 'sine', 0.2), 120);
      },

      // Wake word detected
      wake: () => {
        playTone(520, 0.1, 'sine', 0.2);
        setTimeout(() => playTone(660, 0.1, 'sine', 0.2), 80);
        setTimeout(() => playTone(880, 0.15, 'sine', 0.25), 160);
      }
    };

    // Remove overlapping/duplicate content between accumulated transcript and new recognition
    // This prevents duplication when speech recognition restarts or fires multiple results
    function removeOverlap(accumulated, newTranscript) {
      if (!accumulated.trim() || !newTranscript.trim()) return newTranscript;

      const accLower = accumulated.trim().toLowerCase();
      const newLower = newTranscript.trim().toLowerCase();

      // Case 1: New transcript is entirely contained in accumulated - skip it completely
      if (accLower.includes(newLower)) {
        return '';
      }

      // Case 2: New transcript starts with content already in accumulated
      // Find if any prefix of new transcript exists at the end of accumulated
      const newWords = newTranscript.trim().split(/\s+/);
      const accWords = accumulated.trim().split(/\s+/);

      // Check if new transcript starts with words from end of accumulated (overlap)
      const maxOverlap = Math.min(20, accWords.length, newWords.length);
      for (let overlapLen = maxOverlap; overlapLen > 0; overlapLen--) {
        const accEnd = accWords.slice(-overlapLen).join(' ').toLowerCase();
        const newStart = newWords.slice(0, overlapLen).join(' ').toLowerCase();
        if (accEnd === newStart) {
          // Found overlap - return only the non-overlapping part
          const nonOverlapping = newWords.slice(overlapLen).join(' ');
          return nonOverlapping ? ' ' + nonOverlapping : '';
        }
      }

      // Case 3: Check if new transcript contains a repeated phrase from accumulated
      // This catches "X X X" patterns where X is repeated
      for (let phraseLen = Math.min(10, accWords.length); phraseLen >= 3; phraseLen--) {
        const phraseEnd = accWords.slice(-phraseLen).join(' ').toLowerCase();
        // Check if this phrase appears multiple times in new transcript
        const phraseRegex = new RegExp(phraseEnd.replace(/[.*+?^${}()|[\]\\]/g, '\\$&'), 'gi');
        const matches = newLower.match(phraseRegex);
        if (matches && matches.length > 1) {
          // Phrase is repeated in new - only keep content after last occurrence
          const lastIndex = newLower.lastIndexOf(phraseEnd);
          const afterLast = newTranscript.trim().substring(lastIndex + phraseEnd.length).trim();
          return afterLast ? ' ' + afterLast : '';
        }
      }

      return newTranscript;
    }

    // DOM Elements
    const micButton = document.getElementById('micButton');
    const micIcon = document.getElementById('micIcon');
    const inputContainer = document.getElementById('inputContainer');
    const textInput = document.getElementById('textInput');
    const sendBtn = document.getElementById('sendBtn');
    const stopBtn = document.getElementById('stopBtn');
    const driverSelect = document.getElementById('driverSelect');
    const recordingIndicator = document.getElementById('recordingIndicator');
    const drivingModeBtn = document.getElementById('drivingModeBtn');
    const drivingIcon = document.getElementById('drivingIcon');

    console.log('[VoideInputBar] Initialized');

    // =========================================================================
    // Driving Mode
    // =========================================================================

    function toggleDrivingMode() {
      isDrivingMode = !isDrivingMode;
      updateDrivingModeUI();

      if (isDrivingMode) {
        // Play activation sound
        sounds.wake();
        // Auto-start listening in driving mode
        if (!appStore.get().isRecording) {
          startRecording();
        }
        console.log('[Voide] Driving mode activated - hands-free experience enabled');
      } else {
        // Play deactivation sound (softer)
        playTone(440, 0.15, 'sine', 0.15);
        isAwake = false;
        console.log('[Voide] Driving mode deactivated');
      }
    }

    function updateDrivingModeUI() {
      if (drivingModeBtn) {
        drivingModeBtn.className = 'w-8 h-8 rounded-lg flex items-center justify-center transition-colors ' +
          (isDrivingMode ? 'text-monokai-green bg-monokai-green/20' : 'text-monokai-gray hover:text-monokai-fg hover:bg-monokai-bg');
        drivingModeBtn.title = isDrivingMode ? 'Driving Mode ON (click to disable)' : 'Driving Mode (hands-free)';
      }
      if (drivingIcon) {
        drivingIcon.setAttribute('stroke', isDrivingMode ? '#a9dc76' : 'currentColor');
      }
    }

    // Bind driving mode toggle
    drivingModeBtn?.addEventListener('click', toggleDrivingMode);

    // Initialize driver selector from store
    const initialDriver = appStore.get().currentDriver || 'claude-sdk';
    if (driverSelect) driverSelect.value = initialDriver;

    // Handle driver selection change
    driverSelect?.addEventListener('change', (e) => {
      appActions.setDriver(e.target.value);
    });

    // =========================================================================
    // API Helpers
    // =========================================================================

    function checkBackendAPI() {
      return fetch(API_BASE_URL + '/state')
        .then(res => res.ok)
        .catch(() => false);
    }

    function saveChat() {
      const app = appStore.get();
      chatActions.saveCurrentChat(app.repoPath, app.currentDriver);
    }

    let saveChatDebounceTimer = null;
    function updateLastMessage(type, content) {
      chatActions.updateLastMessage(type, content);
      clearTimeout(saveChatDebounceTimer);
      saveChatDebounceTimer = setTimeout(saveChat, 500);
    }

    function addMessage(type, content, header) {
      const app = appStore.get();
      const driverName = app.currentDriver === 'claude-sdk' ? 'Claude SDK' :
                         app.currentDriver === 'openai' ? 'OpenAI' :
                         app.currentDriver === 'ollama' ? 'Ollama' : 'AI';
      const headerText = header || (type === 'user' ? 'You' : type === 'assistant' ? driverName : type === 'system' ? 'System' : 'Error');
      chatActions.addMessage(type, content, headerText);
      saveChat();
    }

    // =========================================================================
    // Command Processing
    // =========================================================================

    // Detect if a command is a question/explanation (simple mode) vs action/task (agentic mode)
    function detectMode(command) {
      const lower = command.toLowerCase().trim();

      // Question patterns - use simple mode for true token-by-token streaming
      const questionPatterns = [
        /^(what|why|how|when|where|who|which|can you explain|could you explain|please explain|tell me|describe|is it|are there|do you|does|did|will|would|should|could|can|may|might)/i,
        /\?$/,  // Ends with question mark
        /^explain\s/i,
        /^describe\s/i,
        /^tell me\s/i,
        /^help me understand/i,
        /^i('m| am) (curious|wondering|confused)/i,
      ];

      // Action patterns - use agentic mode with tool access
      const actionPatterns = [
        /^(fix|create|add|remove|delete|update|change|modify|refactor|implement|write|build|make|generate|run|execute|install|setup|configure|debug|test)/i,
        /^please (fix|create|add|remove|delete|update|change|modify|refactor|implement|write|build|make)/i,
        /\b(in my|in the|this|the) (code|file|project|app|application|repo|repository|codebase)\b/i,
        /\b(lint|format|compile|build|deploy|push|commit|merge)\b/i,
      ];

      // Check for action patterns first (higher priority)
      for (const pattern of actionPatterns) {
        if (pattern.test(lower)) {
          return 'agentic';
        }
      }

      // Check for question patterns
      for (const pattern of questionPatterns) {
        if (pattern.test(lower)) {
          return 'simple';
        }
      }

      // Default to agentic for safety (can use tools if needed)
      return 'agentic';
    }

    function processWithStreaming(command) {
      return new Promise((resolve, reject) => {
        let fullContent = '';
        let currentEvent = '';
        const app = appStore.get();
        const chat = chatStore.get();

        // Detect mode based on command type
        const mode = detectMode(command);
        console.log('[Voide] Detected mode:', mode, 'for command:', command.substring(0, 50) + '...');

        // Build conversation history for context (exclude the loading message we just added)
        const history = chat.messages.slice(0, -1).map(m => ({
          role: m.type === 'user' ? 'user' : 'assistant',
          content: m.content
        })).filter(m => m.role === 'user' || m.role === 'assistant');

        console.log('[Voide] Sending request with', history.length, 'history messages, sessionId:', chat.sessionId || 'NONE');

        fetch(API_BASE_URL + '/process/stream', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            command: command,
            driver: app.currentDriver,
            repository: app.repoPath,
            sessionId: chat.sessionId,
            history: history,
            mode: mode
          })
        }).then(response => {
          if (!response.ok) throw new Error('Stream request failed');

          const reader = response.body.getReader();
          const decoder = new TextDecoder();
          let buffer = '';

          function readChunk() {
            reader.read().then(result => {
              if (result.done) {
                resolve({ message: fullContent, hasChanges: false });
                return;
              }

              buffer += decoder.decode(result.value, { stream: true });
              const lines = buffer.split('\n');
              buffer = lines.pop() || '';

              for (const line of lines) {
                const trimmed = line.trim();
                if (!trimmed) continue;

                if (trimmed.startsWith('event: ')) {
                  currentEvent = trimmed.substring(7);
                  continue;
                }

                if (trimmed.startsWith('data: ')) {
                  try {
                    const data = JSON.parse(trimmed.substring(6));

                    if (currentEvent === 'session' && data.sessionId) {
                      chatActions.setSessionId(data.sessionId);
                      saveChat(); // Persist sessionId immediately
                    } else if (currentEvent === 'chunk' && data.text) {
                      fullContent += data.text;
                      updateLastMessage('assistant', fullContent);
                    } else if (currentEvent === 'tool' && data.tool) {
                      let toolInfo = data.tool;
                      if (data.input) {
                        if (data.tool === 'Read' && data.input.file_path) {
                          toolInfo = 'Reading ' + data.input.file_path.split('/').pop();
                        } else if (data.tool === 'Edit' && data.input.file_path) {
                          toolInfo = 'Editing ' + data.input.file_path.split('/').pop();
                        } else if (data.tool === 'Write' && data.input.file_path) {
                          toolInfo = 'Writing ' + data.input.file_path.split('/').pop();
                        } else if (data.tool === 'Bash' && data.input.command) {
                          toolInfo = '$ ' + data.input.command.substring(0, 40) + (data.input.command.length > 40 ? '...' : '');
                        } else if (data.tool === 'Glob' && data.input.pattern) {
                          toolInfo = 'Finding ' + data.input.pattern;
                        } else if (data.tool === 'Grep' && data.input.pattern) {
                          toolInfo = 'Searching "' + data.input.pattern + '"';
                        } else if (data.tool === 'Task' && data.input.description) {
                          toolInfo = 'Task: ' + data.input.description;
                        }
                      }
                      fullContent += '\n`' + toolInfo + '`';
                      updateLastMessage('assistant', fullContent);
                    } else if (currentEvent === 'prompt') {
                      chatActions.setPendingPrompt({
                        id: data.id || Date.now().toString(),
                        text: data.text || 'Please select an option:',
                        options: data.options || ['y', 'n'],
                        labels: data.labels || data.options || ['Yes', 'No']
                      });
                    } else if (currentEvent === 'done') {
                      chatActions.clearPendingPrompt();
                      resolve({ message: fullContent, hasChanges: data.hasChanges || false });
                      return;
                    } else if (currentEvent === 'error') {
                      chatActions.clearPendingPrompt();
                      reject(new Error(data.error || 'Stream error'));
                      return;
                    }
                  } catch (e) {}
                }
              }
              readChunk();
            }).catch(reject);
          }
          readChunk();
        }).catch(reject);
      });
    }

    // Generate a smart title for the chat using AI
    function generateChatTitle(chatId, prompt) {
      fetch(API_BASE_URL + '/title', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ prompt })
      })
      .then(res => res.json())
      .then(data => {
        if (data.title) {
          chatActions.setChatTitle(chatId, data.title);
        }
      })
      .catch(err => {
        console.log('[Voide] Failed to generate title:', err.message);
      });
    }

    function processCommand(command) {
      if (!command.trim()) return;

      const chat = chatStore.get();
      const app = appStore.get();
      let isNewChat = false;
      let newChatId = null;

      if (!chat.currentChatId) {
        newChatId = chatActions.startNewChat(app.repoPath, app.currentDriver, {
          type: 'user',
          content: command,
          header: 'You',
          timestamp: Date.now()
        });
        isNewChat = true;
      } else {
        addMessage('user', command);
      }

      appActions.setTerminalTitle('Processing...');

      if (!app.repoPath) {
        addMessage('error', 'Please enter a repository URL or path first.');
        appActions.setTerminalTitle('Voide - Ready');
        return;
      }

      appActions.setProcessing(true);
      addMessage('assistant', '...');

      // Play processing sound in driving mode
      if (isDrivingMode) {
        sounds.processing();
      }

      checkBackendAPI().then(hasBackend => {
        if (hasBackend) {
          return processWithStreaming(command);
        } else if (app.currentDriver === 'mock') {
          return new Promise(resolve => {
            setTimeout(() => {
              resolve({
                message: '[Mock] Processing: "' + command + '"\n\nThis is a simulated response.',
                hasChanges: command.toLowerCase().includes('fix')
              });
            }, 1500);
          });
        } else {
          return Promise.reject(new Error('Backend API not available. Start the server at localhost:3008.'));
        }
      }).then(response => {
        if (response.hasChanges) {
          appActions.setHasChanges(true);
          addMessage('system', 'Changes staged. Click "Commit Changes" to create a commit.');
        }
        appActions.setTerminalTitle('Voide - Ready');

        // Generate a smart title for new chats
        if (isNewChat && newChatId) {
          generateChatTitle(newChatId, command);
        }

        // Driving mode: play done sound and auto-TTS response
        if (isDrivingMode) {
          sounds.done();
          // Auto-speak the response after a brief delay
          setTimeout(() => {
            if (response.message && window.voide?.speak) {
              window.voide.speak(response.message, 'auto-tts');
            }
          }, 400);
        }
      }).catch(error => {
        chatActions.removeLastMessage();
        addMessage('error', 'Failed: ' + error.message);
        appActions.setTerminalTitle('Voide - Error');

        // Play error sound in driving mode
        if (isDrivingMode) {
          sounds.error();
        }
      }).finally(() => {
        appActions.setProcessing(false);
      });
    }

    // =========================================================================
    // Input Handlers
    // =========================================================================

    function handleInputChange(e) {
      const el = e.target;
      el.style.height = 'auto';
      el.style.height = Math.min(el.scrollHeight, 160) + 'px';
      chatActions.setInputText(el.value);

      // Sync keyboard edits with voice transcript so they stay in sync
      accumulatedTranscript = el.value + (el.value ? ' ' : '');
      appActions.setTranscript(el.value);
    }

    function handleInputKeydown(e) {
      if (e.key === 'Enter' && !e.shiftKey) {
        e.preventDefault();
        handleTextSubmit();
      }
    }

    function handleTextSubmit() {
      const chat = chatStore.get();
      let text = chat.inputText.trim();

      // Check if text ends with "send", "go", or "submit" (voice command triggers)
      const sendTriggers = /\s+(send|go|submit)$/i;
      if (sendTriggers.test(text)) {
        text = text.replace(sendTriggers, '').trim();
      }
      // Also handle standalone triggers - do nothing if that's all there is
      if (/^(send|go|submit)$/i.test(text)) {
        return;
      }

      if (text && !appStore.get().isProcessing) {
        chatActions.clearInput();
        if (textInput) {
          textInput.value = '';
          textInput.style.height = 'auto';
        }
        processCommand(text);
      }
    }

    function handleSendClick() {
      handleTextSubmit();
    }

    // =========================================================================
    // Speech Recognition
    // =========================================================================

    // Convert spoken punctuation words to actual symbols
    const punctuationMap = [
      // Common punctuation
      [/\bperiod\b/gi, '.'],
      [/\bfull stop\b/gi, '.'],
      [/\bcomma\b/gi, ','],
      [/\bquestion mark\b/gi, '?'],
      [/\bexclamation mark\b/gi, '!'],
      [/\bexclamation point\b/gi, '!'],
      [/\bcolon\b/gi, ':'],
      [/\bsemicolon\b/gi, ';'],
      [/\bsemi colon\b/gi, ';'],
      // Quotes
      [/\bquote\b/gi, '"'],
      [/\bend quote\b/gi, '"'],
      [/\bopen quote\b/gi, '"'],
      [/\bclose quote\b/gi, '"'],
      [/\bsingle quote\b/gi, "'"],
      [/\bapostrophe\b/gi, "'"],
      // Brackets
      [/\bopen paren\b/gi, '('],
      [/\bclose paren\b/gi, ')'],
      [/\bopen parenthesis\b/gi, '('],
      [/\bclose parenthesis\b/gi, ')'],
      [/\bleft paren\b/gi, '('],
      [/\bright paren\b/gi, ')'],
      [/\bopen bracket\b/gi, '['],
      [/\bclose bracket\b/gi, ']'],
      [/\bleft bracket\b/gi, '['],
      [/\bright bracket\b/gi, ']'],
      [/\bopen brace\b/gi, '{'],
      [/\bclose brace\b/gi, '}'],
      [/\bleft brace\b/gi, '{'],
      [/\bright brace\b/gi, '}'],
      [/\bopen curly\b/gi, '{'],
      [/\bclose curly\b/gi, '}'],
      // Special characters
      [/\bhyphen\b/gi, '-'],
      [/\bdash\b/gi, '-'],
      [/\bunderscore\b/gi, '_'],
      [/\bslash\b/gi, '/'],
      [/\bforward slash\b/gi, '/'],
      [/\bbackslash\b/gi, '\\'],
      [/\bback slash\b/gi, '\\'],
      [/\bpipe\b/gi, '|'],
      [/\bampersand\b/gi, '&'],
      [/\bat sign\b/gi, '@'],
      [/\bhash\b/gi, '#'],
      [/\bhashtag\b/gi, '#'],
      [/\bpound sign\b/gi, '#'],
      [/\basterisk\b/gi, '*'],
      [/\bstar\b/gi, '*'],
      [/\bpercent\b/gi, '%'],
      [/\bpercent sign\b/gi, '%'],
      [/\bcaret\b/gi, '^'],
      [/\btilde\b/gi, '~'],
      [/\bbacktick\b/gi, '`'],
      [/\bgrave\b/gi, '`'],
      [/\bellipsis\b/gi, '...'],
      [/\bdot dot dot\b/gi, '...'],
      // Comparison operators
      [/\bequals\b/gi, '='],
      [/\bequal sign\b/gi, '='],
      [/\bless than\b/gi, '<'],
      [/\bgreater than\b/gi, '>'],
      // New line
      [/\bnew line\b/gi, '\n'],
      [/\bnewline\b/gi, '\n'],
    ];

    function convertSpokenPunctuation(text) {
      let result = text;
      for (const [pattern, replacement] of punctuationMap) {
        result = result.replace(pattern, replacement);
      }
      // Clean up extra spaces around punctuation
      result = result.replace(/\s+([.,!?;:])/g, '$1');
      result = result.replace(/([(\[{])\s+/g, '$1');
      result = result.replace(/\s+([)\]}])/g, '$1');
      return result;
    }

    function initSpeechRecognition() {
      if (!speechRecognition.isSupported) {
        appActions.setSpeechSupported(false);
        return false;
      }

      speechRecognition.on('start', () => {
        const app = appStore.get();
        if (!app.isRecording) {
          appActions.setTranscript('');
        }
        appActions.setRecording(true);
        // Play listening sound in driving mode
        if (isDrivingMode) {
          sounds.listening();
        }
      });

      speechRecognition.on('result', (data) => {
        // Skip processing during restart or send to prevent race conditions
        if (isRestarting || isSending) return;

        // Skip exact duplicate transcripts (browser sometimes fires same result multiple times)
        const currentTranscript = data.transcript?.trim() || '';
        if (currentTranscript === lastProcessedTranscript) {
          return;
        }
        lastProcessedTranscript = currentTranscript;

        // Remove overlap to prevent duplication when recognition restarts
        const cleanedTranscript = removeOverlap(accumulatedTranscript, data.transcript);
        const rawTranscript = accumulatedTranscript + cleanedTranscript;
        const trimmed = rawTranscript.trim().toLowerCase();

        // Wake word detection for driving mode
        // Wake words: "hey buddy", "hey void", "okay buddy", "ok buddy"
        const wakeWordPatterns = [
          /^hey buddy/i,
          /^hey void/i,
          /^okay buddy/i,
          /^ok buddy/i,
          /^yo buddy/i,
        ];

        if (isDrivingMode && !isAwake) {
          // In driving mode, wait for wake word
          for (const pattern of wakeWordPatterns) {
            if (pattern.test(trimmed)) {
              // Wake word detected - activate listening
              isAwake = true;
              sounds.wake();
              // Clear the wake word from transcript
              const afterWake = trimmed.replace(pattern, '').trim();
              accumulatedTranscript = afterWake ? afterWake + ' ' : '';
              appActions.setTranscript(afterWake);
              chatActions.setInputText(afterWake);
              if (textInput) {
                textInput.value = afterWake;
              }
              console.log('[Voide] Wake word detected - listening for command');
              return;
            }
          }
          // No wake word - ignore input in driving mode when not awake
          return;
        }

        // Voice commands for TTS control (work anytime, not just in driving mode)
        // "repeat" or "say again" - repeat the last assistant response
        if (trimmed === 'repeat' || trimmed === 'say again' || trimmed === 'repeat that' ||
            trimmed.endsWith(' repeat') || trimmed.endsWith(' say again')) {
          isRestarting = true;
          accumulatedTranscript = '';
          appActions.setTranscript('');
          if (textInput) {
            textInput.value = '';
            textInput.style.height = 'auto';
          }

          // Find and speak the last assistant message
          const messages = chatStore.get().messages;
          const lastAssistant = [...messages].reverse().find(m => m.type === 'assistant' && m.content !== '...');
          if (lastAssistant && window.voide?.speak) {
            sounds.listening(); // Acknowledge
            window.voide.speak(lastAssistant.content, 'repeat-tts');
          }

          speechRecognition.stop();
          setTimeout(() => {
            isRestarting = false;
            const app = appStore.get();
            if (app.isRecording) speechRecognition.start();
          }, 300);
          return;
        }

        // "quiet", "shut up", "be quiet", "silence" - stop TTS
        if (trimmed === 'quiet' || trimmed === 'shut up' || trimmed === 'be quiet' ||
            trimmed === 'silence' || trimmed === 'stop talking' ||
            trimmed.endsWith(' quiet') || trimmed.endsWith(' shut up')) {
          isRestarting = true;
          accumulatedTranscript = '';
          appActions.setTranscript('');
          if (textInput) {
            textInput.value = '';
            textInput.style.height = 'auto';
          }

          // Stop any current TTS
          if (window.voide?.stopSpeaking) {
            window.voide.stopSpeaking();
            sounds.listening(); // Soft acknowledgment
          }

          speechRecognition.stop();
          setTimeout(() => {
            isRestarting = false;
            const app = appStore.get();
            if (app.isRecording) speechRecognition.start();
          }, 300);
          return;
        }

        // "reset" clears the prompt
        if (trimmed.endsWith(' reset') || trimmed === 'reset') {
          isRestarting = true;
          accumulatedTranscript = '';
          lastProcessedTranscript = '';
          appActions.setTranscript('');
          chatActions.setInputText('');
          if (textInput) {
            textInput.value = '';
            textInput.style.height = 'auto';
          }
          speechRecognition.stop();
          setTimeout(() => {
            isRestarting = false;
            const app = appStore.get();
            if (app.isRecording) speechRecognition.start();
          }, 300);
          return;
        }

        // "oops" deletes last word only (preserves newlines)
        if (trimmed.endsWith(' oops') || trimmed === 'oops') {
          isRestarting = true;
          let text = rawTranscript.replace(/\s*oops\s*$/i, '');
          text = text.replace(/[ \t]*[^ \t\n]+[ \t]*$/, '');
          const newTranscript = convertSpokenPunctuation(text);
          accumulatedTranscript = newTranscript + (newTranscript ? ' ' : '');
          appActions.setTranscript(newTranscript);
          chatActions.setInputText(newTranscript);
          if (textInput) {
            textInput.value = newTranscript;
            textInput.style.height = 'auto';
            textInput.style.height = Math.min(textInput.scrollHeight, 120) + 'px';
          }
          speechRecognition.stop();
          setTimeout(() => {
            isRestarting = false;
            const app = appStore.get();
            if (app.isRecording) speechRecognition.start();
          }, 300);
          return;
        }

        // "go", "send", or "submit" submits the prompt
        if (/(^|\s)(go|send|submit)$/i.test(trimmed)) {
          // Double protection: flag + timestamp debounce (500ms)
          const now = Date.now();
          if (isSending || (now - lastSendTime) < 500) {
            return; // Already sending or sent recently
          }
          isSending = true;
          lastSendTime = now;

          const cleanTranscript = convertSpokenPunctuation(rawTranscript.replace(/\s*(go|send|submit)\s*$/i, '').trim());
          if (cleanTranscript) {
            // Keep mic on - just clear transcript and restart recognition
            isRestarting = true;
            accumulatedTranscript = '';
            lastProcessedTranscript = '';
            appActions.setTranscript('');
            chatActions.clearInput();
            if (textInput) {
              textInput.value = '';
              textInput.style.height = 'auto';
            }
            // Reset awake state in driving mode - user needs to say wake word again
            if (isDrivingMode) {
              isAwake = false;
            }
            speechRecognition.stop();
            setTimeout(() => {
              processCommand(cleanTranscript);
              isSending = false;
              isRestarting = false;
              // Restart mic if it was on
              const app = appStore.get();
              if (app.isRecording) speechRecognition.start();
            }, 100);
          } else {
            isSending = false;
          }
          return;
        }

        // "stop" or "pause" - turn off the mic
        if (trimmed === 'stop' || trimmed === 'pause' || trimmed.endsWith(' stop') || trimmed.endsWith(' pause')) {
          accumulatedTranscript = '';
          lastProcessedTranscript = '';
          appActions.setTranscript('');
          appActions.setRecording(false);
          speechRecognition.stop();
          if (textInput) {
            textInput.value = '';
            textInput.style.height = 'auto';
          }
          return;
        }

        // "clear chat" or "new chat" - clear conversation
        if (trimmed === 'clear chat' || trimmed === 'new chat' || trimmed.endsWith(' clear chat') || trimmed.endsWith(' new chat')) {
          isRestarting = true;
          accumulatedTranscript = '';
          appActions.setTranscript('');
          chatActions.clearMessages();
          if (textInput) {
            textInput.value = '';
            textInput.style.height = 'auto';
          }
          speechRecognition.stop();
          setTimeout(() => {
            isRestarting = false;
            const app = appStore.get();
            if (app.isRecording) speechRecognition.start();
          }, 300);
          return;
        }

        // "cancel" - stop Claude mid-response
        if (trimmed === 'cancel' || trimmed.endsWith(' cancel')) {
          isRestarting = true;
          accumulatedTranscript = '';
          appActions.setTranscript('');
          cancelProcessing();
          if (textInput) {
            textInput.value = '';
            textInput.style.height = 'auto';
          }
          speechRecognition.stop();
          setTimeout(() => {
            isRestarting = false;
            const app = appStore.get();
            if (app.isRecording) speechRecognition.start();
          }, 300);
          return;
        }

        // Convert spoken punctuation to symbols and update display
        const fullTranscript = convertSpokenPunctuation(rawTranscript);
        appActions.setTranscript(fullTranscript);
      });

      speechRecognition.on('end', () => {
        // Don't auto-restart during controlled restart (like oops command)
        // The command handler will restart recognition itself
        if (isRestarting) return;

        const app = appStore.get();
        if (app.isRecording) {
          // Store converted transcript for continuation
          accumulatedTranscript = (app.transcript || '') + ' ';
          speechRecognition.start();
        } else {
          accumulatedTranscript = '';
        }
      });

      speechRecognition.on('error', (data) => {
        stopRecording();
        if (data.code !== 'aborted' && data.code !== 'no-speech') {
          addMessage('error', data.message);
        }
      });

      appActions.setSpeechSupported(true);
      return true;
    }

    function startRecording() {
      const app = appStore.get();
      if (!app.speechSupported || app.isRecording) return;
      appActions.setTranscript('');
      accumulatedTranscript = '';
      lastProcessedTranscript = '';
      speechRecognition.start();
    }

    function stopRecording() {
      const app = appStore.get();
      if (app.transcript && app.transcript.trim()) {
        chatActions.setInputText(app.transcript.trim());
        if (textInput) textInput.value = app.transcript.trim();
      }
      appActions.setRecording(false);
      speechRecognition.stop();
    }

    function toggleRecording() {
      const app = appStore.get();
      if (app.isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    }

    // =========================================================================
    // Git Actions
    // =========================================================================

    function commitChanges() {
      if (!appStore.get().hasChanges) return;

      addMessage('system', 'Creating commit...');

      checkBackendAPI().then(hasBackend => {
        if (hasBackend) {
          return fetch(API_BASE_URL + '/commit', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' }
          }).then(res => res.json());
        }
        return { success: true, hash: 'mock-commit-hash' };
      }).then(response => {
        addMessage('system', 'Committed: ' + (response.hash || 'success'));
        appActions.setHasChanges(false);
      }).catch(error => {
        addMessage('error', 'Failed: ' + error.message);
      });
    }

    function pushChanges() {
      addMessage('system', 'Pushing to remote...');

      checkBackendAPI().then(hasBackend => {
        if (hasBackend) {
          return fetch(API_BASE_URL + '/push', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' }
          });
        }
        return Promise.resolve();
      }).then(() => {
        addMessage('system', 'Pushed successfully.');
      }).catch(error => {
        addMessage('error', 'Failed: ' + error.message);
      });
    }

    function cancelProcessing() {
      fetch(API_BASE_URL + '/cancel', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({})
      }).then(res => res.json()).then(data => {
        appActions.setProcessing(false);
        const messages = chatStore.get().messages;
        if (messages.length > 0) {
          const lastMsg = messages[messages.length - 1];
          if (lastMsg && lastMsg.type === 'assistant') {
            updateLastMessage('assistant', lastMsg.content + '\n\n— *Stopped*');
          }
        }
      }).catch(error => {
        // Even on error, stop processing locally
        appActions.setProcessing(false);
        const messages = chatStore.get().messages;
        if (messages.length > 0) {
          const lastMsg = messages[messages.length - 1];
          if (lastMsg && lastMsg.type === 'assistant') {
            updateLastMessage('assistant', lastMsg.content + '\n\n— *Stopped*');
          }
        }
      });
    }

    // =========================================================================
    // Event Bindings
    // =========================================================================

    // Button click handlers
    micButton?.addEventListener('click', toggleRecording);
    sendBtn?.addEventListener('click', handleSendClick);
    stopBtn?.addEventListener('click', cancelProcessing);

    // Text input handlers
    textInput?.addEventListener('input', handleInputChange);
    textInput?.addEventListener('keydown', handleInputKeydown);

    // Global keyboard shortcuts
    document.addEventListener('keydown', (e) => {
      if (e.code === 'Space' && !e.repeat) {
        const active = document.activeElement;
        const isInput = active && (active.tagName === 'INPUT' || active.tagName === 'TEXTAREA');
        if (!isInput) {
          e.preventDefault();
          toggleRecording();
        }
      }
    });

    // =========================================================================
    // State Subscriptions
    // =========================================================================

    const thinkingIndicator = document.getElementById('thinkingIndicator');
    const thinkingTimer = document.getElementById('thinkingTimer');
    let timerInterval = null;
    let timerStart = null;

    function startTimer() {
      timerStart = Date.now();
      if (thinkingTimer) thinkingTimer.textContent = '0.0s';
      timerInterval = setInterval(() => {
        if (thinkingTimer && timerStart) {
          const elapsed = ((Date.now() - timerStart) / 1000).toFixed(1);
          thinkingTimer.textContent = `${elapsed}s`;
        }
      }, 100);
    }

    function stopTimer() {
      if (timerInterval) {
        clearInterval(timerInterval);
        timerInterval = null;
      }
      timerStart = null;
    }

    appStore.subscribe((state) => {
      // Show/hide thinking indicator above input
      if (thinkingIndicator) {
        if (state.isProcessing) {
          thinkingIndicator.classList.remove('hidden');
          if (!timerInterval) startTimer();
        } else {
          thinkingIndicator.classList.add('hidden');
          stopTimer();
        }
      }

      // Show/hide stop button based on processing state
      if (stopBtn) {
        if (state.isProcessing) {
          stopBtn.classList.remove('hidden');
        } else {
          stopBtn.classList.add('hidden');
        }
      }

      // Mic button state - cyan when ready to listen
      if (micButton) {
        micButton.className = 'w-8 h-8 rounded-lg flex items-center justify-center transition-colors ' +
          (state.isRecording ? 'text-monokai-cyan bg-monokai-cyan/10' : 'text-monokai-gray hover:text-monokai-fg hover:bg-monokai-bg');
      }
      if (micIcon) micIcon.setAttribute('stroke', state.isRecording ? '#78dce8' : 'currentColor');

      // Recording indicator
      if (recordingIndicator) {
        if (state.isRecording) {
          recordingIndicator.classList.remove('hidden');
        } else {
          recordingIndicator.classList.add('hidden');
        }
      }

      // Input container state - cyan border when ready
      if (inputContainer) {
        inputContainer.className = 'bg-monokai-bg-dark border rounded-2xl px-4 py-3 ' +
          (state.isRecording ? 'border-monokai-cyan' : 'border-monokai-border');
      }

      // Update placeholder and value based on recording state
      if (textInput) {
        textInput.placeholder = 'Type / for commands';
        if (state.isRecording && state.transcript) {
          textInput.value = state.transcript;
          textInput.style.height = 'auto';
          textInput.style.height = Math.min(textInput.scrollHeight, 160) + 'px';
          chatActions.setInputText(state.transcript);
        }
      }

      // Sync driver selector
      if (driverSelect && state.currentDriver) {
        driverSelect.value = state.currentDriver;
      }
    });

    // Initialize speech recognition
    initSpeechRecognition();

    // Expose to window.voide for other components
    window.voide = window.voide || {};
    Object.assign(window.voide, {
      toggleRecording,
      startRecording,
      stopRecording,
      handleInputChange,
      handleInputKeydown,
      handleSendClick,
      handleTextSubmit,
      cancelProcessing,
      processCommand,
      addMessage,
      // Driving mode
      toggleDrivingMode,
      isDrivingMode: () => isDrivingMode,
      sounds
    });
  }

  init();
})();
</script>
